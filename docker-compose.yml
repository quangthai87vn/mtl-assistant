services:
  db:
    build: ./db
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: law_assistant
    ports:
      - "5435:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped


  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app/backend
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DATABASE}
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DATABASE=${POSTGRES_DATABASE}
      #- OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      #- OPENAI_API_KEY=${LITELLM_MASTER_KEY}
      - OPENAI_API_KEY=${LITELLM_MASTER_KEY}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - LLM_MODEL=${LLM_MODEL}
      - LIGHTRAG_WORKING_DIR=/app/backend/data
      - LIGHTRAG_WORKER_TIMEOUT=600
      - SUMMARY_LANGUAGE=Vietnamese
      - 'ENTITY_TYPES=["Văn bản pháp luật", "Điều khoản", "Cơ quan ban hành", "Đối tượng áp dụng", "Hành vi vi phạm", "Hình thức xử phạt", "Thời hạn", "Khái niệm pháp lý"]'
    depends_on:
      - db
    

  rag-ui:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8001:8001"
    volumes:
      - ./backend:/app/backend
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DATABASE}
      - POSTGRES_HOST=db
      - POSTGRES_PORT=5432
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DATABASE=${POSTGRES_DATABASE}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - EMBEDDING_MODEL=${EMBEDDING_MODEL}
      - LLM_MODEL=${LLM_MODEL}
      - LIGHTRAG_WORKING_DIR=/app/backend/data
      - SUMMARY_LANGUAGE=Vietnamese
      - 'ENTITY_TYPES=["Văn bản pháp luật", "Điều khoản", "Cơ quan ban hành", "Đối tượng áp dụng", "Hành vi vi phạm", "Hình thức xử phạt", "Thời hạn", "Khái niệm pháp lý"]'
      # Storage Backend
      - LIGHTRAG_KV_STORAGE=PGKVStorage
      - LIGHTRAG_VECTOR_STORAGE=PGVectorStorage
      - LIGHTRAG_GRAPH_STORAGE=PGGraphStorage
      - LIGHTRAG_DOC_STATUS_STORAGE=PGDocStatusStorage
      # LLM & Embedding Binding (OpenRouter)
      - LLM_BINDING=openai
      - LLM_BINDING_HOST=http://litellm:4000/v1
      - LLM_BINDING_API_KEY=${LITELLM_MASTER_KEY}
     # - LLM_BINDING_API_KEY=${OPENROUTER_API_KEY}
     # - LLM_BINDING_HOST=https://openrouter.ai/api/v1
      - EMBEDDING_BINDING=openai 
      - EMBEDDING_BINDING_HOST=http://litellm:4000/v1
      - EMBEDDING_BINDING_API_KEY=${LITELLM_MASTER_KEY}
     #- EMBEDDING_BINDING_API_KEY=${OPENROUTER_API_KEY}
     # - EMBEDDING_BINDING_HOST=https://openrouter.ai/api/v1
      #- EMBEDDING_DIM=1536 # ollama-embed 
      - EMBEDDING_DIM=${EMBEDDING_DIM} #vi-embed
      #- EMBEDDING_DIM=1024  #bge-m3

      - EMBEDDING_TIMEOUT=600
      - EMBEDDING_FUNC_MAX_ASYNC=2
      - LLM_TIMEOUT=600
      - LIGHTRAG_WORKER_TIMEOUT=600
    command: lightrag-server --host 0.0.0.0 --port 8001 --working-dir /app/backend/data
    depends_on:
      - db
      - litellm
      - ollama
    restart: unless-stopped

  
  litellm:
    image: docker.litellm.ai/berriai/litellm:main-latest
    ports:
      - "4000:4000"
    env_file:
      - .env
    environment:
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
      - DATABASE_URL=postgresql://postgres:postgres@db:5432/law_assistant
      - LITELLM_SALT_KEY=mtl-salt-key
    volumes:
      - ./litellm_config.yaml:/app/config.yaml:ro
    entrypoint: ["sh", "-lc"]
    command: ["litellm --config /app/config.yaml --host 0.0.0.0 --port 4000 --drop_params"]
    depends_on:
      - ollama
      - vi-embed-server
    restart: unless-stopped



  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    volumes:
      - ollama_data:/root/.ollama
    restart: unless-stopped
    

  vi-embed-server:
    build:
      context: ./vi-embed-server
      dockerfile: Dockerfile
    ports:
      - "8002:8002"
    environment:
      - MODEL_ID=dangvantuan/vietnamese-document-embedding
      - DEVICE=cpu
      - MAX_BATCH=32
    volumes:
      - hf_cache:/root/.cache/huggingface
    restart: unless-stopped


volumes:
  postgres_data:
  ollama_data:
    name: ollama_data
  hf_cache:
